#!/bin/bash -x

printf "\n[pipeline-start] $(date)\n\n"

export REQUEST_ID=$1
RUN_DIR=$2
TASK_NAME="sti"

ARTIFACTS_HOSTNAME=artifacts.dev.testing-farm.io
ARTIFACTS_ROOT=/archive
TEMPLATE_RUNNING=/templates/running/index.html

[ -z "$REQUEST_TIMEOUT" ] && REQUEST_TIMEOUT=4h

[ -z "$REQUEST_ID" ] && { echo "No request ID given"; exit 1; }
[ -z "$RUN_DIR" ] && { echo "No run directory given"; exit 1; }

REQUEST_ARCHIVE_DIR=${ARCHIVE_DIR}/${REQUEST_ID}

archive() {
    WHAT=$1
    WHERE=$2

    if [ ! -e $WHAT ]; then
        echo "Artifact '$WHAT' not found, skipping archivation"
        return
    fi

    rsync -avrz $WHAT ${ARTIFACTS_HOSTNAME}:${ARTIFACTS_ROOT}/${REQUEST_ID}/${WHERE}
}

# create progress page
if [ -z "$NO_ARCHIVE" ]; then
    ssh $ARTIFACTS_HOSTNAME mkdir -p ${ARTIFACTS_ROOT}/${REQUEST_ID}
    ssh $ARTIFACTS_HOSTNAME cp $TEMPLATE_RUNNING ${ARTIFACTS_ROOT}/${REQUEST_ID}
fi

# rpmlist on worker
rpm -qa > rpmlist-worker.txt

# run citool via container with a timeout
timeout --preserve-status --foreground --signal=SIGUSR1 $REQUEST_TIMEOUT \
citool-container.sh rules-engine-empty:rules-engine \
                    testing-farm-request --request-id $REQUEST_ID \
                    ansible \
                    artemis \
                    fedora-copr:copr \
                    guest-setup-testing-farm:guest-setup \
                    install-copr-build \
                    install-koji-build-execute \
                    install-repository \
                    guess-environment-testing-farm-request:guess-environment \
                    dist-git-testing-farm:dist-git \
                    coldstore \
                    testing-farm-request-state-reporter \
                    test-scheduler-sti \
                    test-schedule-runner-sti \
                    test-scheduler \
                    test-schedule-runner \
                    test-schedule-report

# skip archivation
[ -n "$NO_ARCHIVE" ] && exit

# citool exposes all output to stderr, archive it as the pipeline log
archive ${RUN_DIR}/logs/${TASK_NAME}.stderr.0 pipeline.log

# this job prints all stuff to stdout, this save it a job log
archive ${RUN_DIR}/logs/${TASK_NAME}.stdout.0 job.log

# sync task logs
TASK_DIR=$(dirname $RUN_DIR)
for path in ${TASK_DIR}/${TASK_NAME}/*; do
    archive $path
done

# create index.html results page, best effort for now
tfxunit2junit.py --issues-url https://gitlab.com/testing-farm/general/-/issues results.xml > results-junit.xml || true
testing-farm-viewer -r results-junit.xml -t "results" || true
archive results-junit.xml
archive index.html

printf "\n[pipeline-end] $(date)"
